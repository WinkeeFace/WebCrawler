
####### HTTPS://DOCS.CLINE.BOT/ #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Cline Documentation Welcome to the Cline documentation - your comprehensive guide to using and extending Cline's capabilities. Here you'll find resources to help you get started, improve your skills, and contribute to the project. Getting Started New to coding? We've prepared a gentle introduction: Getting Started for New Coders Improving Your Prompting Skills Want to communicate more effectively with Cline? Explore: Prompt Engineering Guide Cline Memory Bank Exploring Cline's Tools Understand Cline's capabilities: Cline Tools Guide Extend Cline with MCP Servers: MCP Overview Building MCP Servers from GitHub Building Custom MCP Servers Contributing to Cline Interested in contributing? We welcome your input: Feel free to submit a pull request Contribution Guidelines Additional Resources Cline GitHub Repository: https://github.com/cline/cline MCP Documentation: https://modelcontextprotocol.org/docs We're always looking to improve this documentation. If you have suggestions or find areas that could be enhanced, please let us know. Your feedback helps make Cline better for everyone! Next Getting Started for New Coders Last updated 16 days ago Getting Started Improving Your Prompting Skills Exploring Cline's Tools Contributing to Cline Additional Resources
####### HTTPS://DOCS.CLINE.BOT/RUNNING-MODELS-LOCALLY/LM-STUDIO #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page ü§ñ Setting Up LM Studio with Cline üìã Prerequisites üöÄ Setup Steps ‚ö†Ô∏è Important Notes üîß Troubleshooting Running Models Locally LM Studio A quick guide to setting up LM Studio for local AI model execution with Cline. Previous Ollama Last updated 22 days ago ü§ñ Setting Up LM Studio with Cline Run AI models locally using LM Studio with Cline. üìã Prerequisites Windows, macOS, or Linux computer with AVX2 support Cline installed in VS Code üöÄ Setup Steps 1. Install LM Studio Visit lmstudio.ai Download and install for your operating system 2. Launch LM Studio Open the installed application You'll see four tabs on the left: Chat , Developer (where you will start the server), My Models (where your downloaded models are stored), Discover (add new models) 3. Download a Model Browse the "Discover" page Select and download your preferred model Wait for download to complete 4. Start the Server Navigate to the "Developer" tab Toggle the server switch to "Running" Note: The server will run at http://localhost:1234 5. Configure Cline Open VS Code Click Cline settings icon Select "LM Studio" as API provider Select your model from the available options ‚ö†Ô∏è Important Notes Start LM Studio before using with Cline Keep LM Studio running in background First model download may take several minutes depending on size Models are stored locally after download üîß Troubleshooting If Cline can't connect to LM Studio: Verify LM Studio server is running (check Developer tab) Ensure a model is loaded Check your system meets hardware requirements
####### HTTPS://DOCS.CLINE.BOT/RUNNING-MODELS-LOCALLY #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook
####### HTTPS://DOCS.CLINE.BOT/RUNNING-MODELS-LOCALLY/OLLAMA #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Running Models Locally Ollama A quick guide to setting up Ollama for local AI model execution with Cline. Previous Read Me First Next LM Studio Last updated 22 days ago üìã Prerequisites Windows, macOS, or Linux computer Cline installed in VS Code üöÄ Setup Steps 1. Install Ollama Visit ollama.com Download and install for your operating system 2. Choose and Download a Model Browse models at ollama.com/search Select model and copy command: Copy ollama run [model-name] Open your Terminal and run the command: Example: Copy ollama run llama2 ‚ú® Your model is now ready to use within Cline! 3. Configure Cline Open VS Code Click Cline settings icon Select "Ollama" as API provider Enter configuration: Base URL: http://localhost:11434/ (default value, can be left as is) Select the model from your available options ‚ö†Ô∏è Important Notes Start Ollama before using with Cline Keep Ollama running in background First model download may take several minutes üîß Troubleshooting If Cline can't connect to Ollama: Verify Ollama is running Check base URL is correct Ensure model is downloaded üìã Prerequisites üöÄ Setup Steps ‚ö†Ô∏è Important Notes üîß Troubleshooting
####### HTTPS://DOCS.CLINE.BOT/RUNNING-MODELS-LOCALLY/READ-ME-FIRST #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Running Local Models with Cline: What You Need to Know ü§ñ Why Local Models Are Different üî¨ What Actually Happens Hardware Requirements üíª Practical Recommendations üí° Common Issues üö® Looking Ahead üîÆ Need Help? ü§ù Running Models Locally Read Me First Previous LiteLLM & Cline (using Codestral) Next Ollama Last updated 17 days ago Running Local Models with Cline: What You Need to Know ü§ñ Cline is a powerful AI coding assistant that uses tool-calling to help you write, analyze, and modify code. While running models locally can save on API costs, there's an important trade-off: local models are significantly less reliable at using these essential tools. Why Local Models Are Different üî¨ When you run a "local version" of a model, you're actually running a drastically simplified copy of the original. This process, called distillation, is like trying to compress a professional chef's knowledge into a basic cookbook ‚Äì you keep the simple recipes but lose the complex techniques and intuition. Local models are created by training a smaller model to imitate a larger one, but they typically only retain 1-26% of the original model's capacity. This massive reduction means: Less ability to understand complex contexts Reduced capability for multi-step reasoning Limited tool-use abilities Simplified decision-making process Think of it like running your development environment on a calculator instead of a computer ‚Äì it might handle basic tasks, but complex operations become unreliable or impossible. What Actually Happens When you run a local model with Cline: Performance Impact üìâ Responses are 5-10x slower than cloud services System resources (CPU, GPU, RAM) get heavily utilized Your computer may become less responsive for other tasks Tool Reliability Issues üõ†Ô∏è Code analysis becomes less accurate File operations may be unreliable Browser automation capabilities are reduced Terminal commands might fail more often Complex multi-step tasks often break down Hardware Requirements üíª You'll need at minimum: Modern GPU with 8GB+ VRAM (RTX 3070 or better) 32GB+ system RAM Fast SSD storage Good cooling solution Even with this hardware, you'll be running smaller, less capable versions of models: Model Size What You Get 7B models Basic coding, limited tool use 14B models Better coding, unstable tool use 32B models Good coding, inconsistent tool use 70B models Best local performance, but requires expensive hardware Put simply, the cloud (API) versions of these models are the full-bore version of the model. The full version of DeepSeek-R1 is 671B. These distilled models are essentially "watered-down" versions of the cloud model. Practical Recommendations üí° Consider This Approach Use cloud models for: Complex development tasks When tool reliability is crucial Multi-step operations Critical code changes Use local models for: Simple code completion Basic documentation When privacy is paramount Learning and experimentation If You Must Go Local Start with smaller models Keep tasks simple and focused Save work frequently Be prepared to switch to cloud models for complex operations Monitor system resources Common Issues üö® "Tool execution failed": Local models often struggle with complex tool chains Slow or incomplete responses: Expect significantly longer processing times System stability: Watch for high GPU/CPU usage and temperature Context limitations: Smaller context windows than cloud models Looking Ahead üîÆ Local model capabilities are improving, but they're not yet a complete replacement for cloud services, especially for Cline's tool-based functionality. Consider your specific needs and hardware capabilities carefully before committing to a local-only approach. Need Help? ü§ù Join our Discord community and r/cline Check the latest compatibility guides Share your experiences with other developers Remember: When in doubt, prioritize reliability over cost savings for important development work.
####### HTTPS://DOCS.CLINE.BOT/CUSTOM-MODEL-CONFIGS/LITELLM-AND-CLINE-USING-CODESTRAL #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Custom Model Configs LiteLLM & Cline (using Codestral) Using LiteLLM with Cline This guide demonstrates how to run a demo for LiteLLM starting with the Codestral model for use with Cline. Prerequisites Docker installed to run the LiteLLM image locally For this example config: A Codestral API Key (different from the Mistral API Keys) Setup Create a .env file and fill in the appropriate field Copy # Tip: Use the following command to generate a random alphanumeric key: # openssl rand -base64 32 | tr -dc 'A-Za-z0-9' | head -c 32 LITELLM_MASTER_KEY=YOUR_LITELLM_MASTER_KEY CODESTRAL_API_KEY=YOUR_CODESTRAL_API_KEY Note: Although this is limited to localhost, it's a good practice set LITELLM_MASTER_KEY to something secure Configuration We'll need to create a config.yaml file to contain our LiteLLM configuration. In this case we'll just have one model, 'codestral-latest' and label it 'codestral' Copy model_list: - model_name: codestral litellm_params: model: codestral/codestral-latest api_key: os.environ/CODESTRAL_API_KEY Running the Demo Startup the LiteLLM docker container Copy docker run \ --env-file .env \ -v $(pwd)/config.yaml:/app/config.yaml \ -p 127.0.0.1:4000:4000 \ ghcr.io/berriai/litellm:main-latest \ --config /app/config.yaml --detailed_debug Setup Cline Once the LiteLLM server is up and running you can set it up in Cline: Base URL should be http://0.0.0.0:4000/v1 API Key should be the one you set in .env for LITELLM_MASTER_KEY Model ID is codestral or whatever you named it under config.yaml Getting Help LiteLLM Documentation Mistral AI Console Cline Discord Community Author: mdp Previous GCP Vertex AI Next Read Me First Last updated 1 month ago
####### HTTPS://DOCS.CLINE.BOT/CUSTOM-MODEL-CONFIGS/GCP-VERTEX-AI #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Step 1: Prepare Your GCP Environment Step 2: Verify Regional and Model Access Step 3: Configure the Cline VS Code Extension Step 4: Authentication and Credentials Setup Step 5: Security, Monitoring, and Best Practices Conclusion Custom Model Configs GCP Vertex AI Overview GCP Vertex AI: A fully managed service that provides access to leading generative AI models‚Äîsuch as Anthropic‚Äôs Claude 3.5 Sonnet v2‚Äîthrough Google Cloud. Learn more about GCP Vertex AI . This guide is tailored for organizations with established GCP environments (leveraging IAM roles, service accounts, and best practices in resource management) to ensure secure and compliant usage. Step 1: Prepare Your GCP Environment 1.1 Create or Use a GCP Project Sign in to the GCP Console: Google Cloud Console . Select or Create a Project: Use an existing project or create a new one dedicated to Vertex AI. (Screenshot suggestion: Project selection/creation screen in the GCP Console) 1.2 Set Up IAM Permissions and Service Accounts Assign Required Roles: Grant your user (or service account) the Vertex AI User role ( roles/aiplatform.user ). For service accounts, also attach the Vertex AI Service Agent role ( roles/aiplatform.serviceAgent ) to enable certain operations. Consider additional predefined roles as needed: Vertex AI Platform Express Admin Vertex AI Platform Express User Vertex AI Migration Service User (Screenshot suggestion: IAM console showing role assignments) Cross-Project Resource Access: For BigQuery tables in different projects, assign the BigQuery Data Viewer role. For Cloud Storage buckets in different projects, assign the Storage Object Viewer role. For external data sources, refer to the GCP Vertex AI Access Control documentation . Step 2: Verify Regional and Model Access 2.1 Choose and Confirm a Region Vertex AI supports eight regions. Select a region that meets your latency, compliance, and capacity needs. Examples include: us-east5 (Columbus, Ohio) us-east1 (South Carolina) us-east4 (Northern Virginia) us-central1 (Iowa) us-west1 (The Dalles, Oregon) us-west4 (Las Vegas, Nevada) europe-west1 (Belgium) asia-southeast1 (Singapore) (Screenshot suggestion: List or map of supported regions in the Vertex AI dashboard) 2.2 Enable the Claude 3.5 Sonnet v2 Model Open Vertex AI Model Garden: In the Cloud Console, navigate to Vertex AI ‚Üí Model Garden . Enable Claude 3.5 Sonnet v2: Locate the model card for Claude 3.5 Sonnet v2 and click Enable . (Screenshot suggestion: Model Garden showing the Claude 3.5 Sonnet v2 model card with the Enable button) Step 3: Configure the Cline VS Code Extension 3.1 Install and Open Cline Download VS Code: Download Visual Studio Code . Install the Cline Extension: Open VS Code. Navigate to the Extensions Marketplace (Ctrl+Shift+X or Cmd+Shift+X). Search for Cline and install the extension. (Screenshot suggestion: VS Code Extensions Marketplace with Cline highlighted) 3.2 Configure Cline Settings Open Cline Settings: Click the settings ‚öôÔ∏è icon within the Cline extension. Set API Provider: Choose GCP Vertex AI from the API Provider dropdown. Enter Your Google Cloud Project ID: Provide the project ID you set up earlier. Select the Region: Choose one of the supported regions (e.g., us-east5 ). Select the Model: From the available list, choose Claude 3.5 Sonnet v2 . Save and Test: Save your settings and test by sending a simple prompt (e.g., ‚ÄúGenerate a Python function to check if a number is prime.‚Äù). (Screenshot suggestion: Cline settings showing project ID, region, and model selection) Step 4: Authentication and Credentials Setup Option A: Using Your Google Account (User Credentials) Install the Google Cloud CLI: Follow the installation guide . Initialize and Authenticate: Copy gcloud init gcloud auth application-default login This sets up Application Default Credentials (ADC) using your Google account. (Screenshot suggestion: Terminal output for successful gcloud auth application-default login ) Restart VS Code: Ensure VS Code is restarted so that the Cline extension picks up the new credentials. Option B: Using a Service Account (JSON Key) Create a Service Account: In the GCP Console, navigate to IAM & Admin > Service Accounts . Create a new service account (e.g., ‚Äúvertex-ai-client‚Äù). Assign Roles: Attach Vertex AI User ( roles/aiplatform.user ). Attach Vertex AI Service Agent ( roles/aiplatform.serviceAgent ). Optionally, add other roles as required. (Screenshot suggestion: Creating a service account with role assignments) Generate a JSON Key: In the Service Accounts section, manage keys for your service account and download the JSON key. Set the Environment Variable: Copy export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json" This instructs Google Cloud client libraries (and Cline) to use this key. (Screenshot suggestion: Terminal showing the export command) Restart VS Code: Launch VS Code from a terminal where the GOOGLE_APPLICATION_CREDENTIALS variable is set. Step 5: Security, Monitoring, and Best Practices 5.1 Enforce Least Privilege Principle of Least Privilege: Only grant the minimum necessary permissions. Custom roles can offer finer control compared to broad predefined roles. Best Practices: Refer to GCP IAM Best Practices . 5.2 Manage Resource Access Project vs. Resource-Level Access: Access can be managed at both levels. Note that resource-level permissions (e.g., for BigQuery or Cloud Storage) add to, but do not override, project-level policies. 5.3 Monitor Usage and Quotas Model Observability Dashboard: In the Vertex AI Console, navigate to the Model Observability dashboard. Monitor metrics such as request throughput, latency, and error rates (including 429 quota errors). (Screenshot suggestion: Model Observability dashboard with error metrics highlighted) Quota Management: If you encounter 429 errors, check the IAM & Admin > Quotas page. Request a quota increase if necessary. Learn more about GCP Vertex AI Quotas . 5.4 Service Agents and Cross-Project Considerations Service Agents: Be aware of the different service agents: Vertex AI Service Agent Vertex AI RAG Data Service Agent Vertex AI Custom Code Service Agent Vertex AI Extension Service Agent Cross-Project Access: For resources in other projects (e.g., BigQuery, Cloud Storage), ensure that the appropriate roles (BigQuery Data Viewer, Storage Object Viewer) are assigned. Conclusion By following these steps, your enterprise team can securely integrate GCP Vertex AI with the Cline VS Code extension to harness the power of Claude 3.5 Sonnet v2 : Prepare Your GCP Environment: Create or use a project, configure IAM with least privilege, and ensure necessary roles (including the Vertex AI Service Agent role) are attached. Verify Regional and Model Access: Confirm that your chosen region supports Claude 3.5 Sonnet v2 and that the model is enabled. Configure Cline in VS Code: Install Cline, enter your project ID, select the appropriate region, and choose the model. Set Up Authentication: Use either user credentials (via gcloud auth application-default login ) or a service account with a JSON key. Implement Security and Monitoring: Adhere to best practices for IAM, manage resource access carefully, and monitor usage with the Model Observability dashboard. For further details, please consult the GCP Vertex AI Documentation and your internal security policies.
Happy coding! This guide will be updated as GCP Vertex AI and Cline evolve. Always refer to the latest documentation for current practices. Copy Previous AWS Bedrock Next LiteLLM & Cline (using Codestral) Last updated 7 days ago
####### HTTPS://DOCS.CLINE.BOT/CUSTOM-MODEL-CONFIGS/AWS-BEDROCK #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Overview Step 1: Prepare Your AWS Environment Step 2: Verify Regional and Model Access Step 3: Configure the Cline VS Code Extension Step 4: Security, Monitoring, and Best Practices Conclusion Custom Model Configs AWS Bedrock Overview AWS Bedrock: A fully managed service that offers access to leading generative AI models (e.g., Anthropic Claude, Amazon Titan) through AWS. Learn more about AWS Bedrock . Cline: A VS Code extension that acts as a coding assistant by integrating with AI models‚Äîempowering developers to generate code, debug, and analyze data. Enterprise Focus: This guide is tailored for organizations with established AWS environments (using IAM roles, AWS SSO, AWS Organizations, etc.) to ensure secure and compliant usage. Step 1: Prepare Your AWS Environment 1.1 Create or Use an IAM Role/User Sign in to the AWS Management Console: AWS Console Access IAM: Search for IAM (Identity and Access Management) in the AWS Console. Either create a new IAM user or use your enterprise‚Äôs AWS SSO to assume a dedicated role for Bedrock access. AWS IAM User Guide 1.2 Attach the Required Policies Attach the Managed Policy: Attach the AmazonBedrockFullAccess managed policy to your user/role. View AmazonBedrockFullAccess Policy Details Confirm Additional Permissions: Ensure your policy includes permissions for model invocation (e.g., bedrock:InvokeModel and bedrock:InvokeModelWithResponseStream ), model listing, and AWS Marketplace actions (like aws-marketplace:Subscribe ). Enterprise Tip: Apply least-privilege practices by scoping resource ARNs and using Service Control Policies (SCPs) to restrict access where necessary. Step 2: Verify Regional and Model Access 2.1 Choose and Confirm a Region Select a Region: AWS Bedrock is available in multiple regions (e.g., US East, Europe, Asia Pacific). Choose the region that meets your latency and compliance needs. AWS Global Infrastructure Verify Model Access: In the AWS Bedrock console, confirm that the models your team requires (e.g., Anthropic Claude, Amazon Titan) are marked as ‚ÄúAccess granted.‚Äù Note: Some advanced models might require an Inference Profile if not available on-demand. 2.2 Set Up AWS Marketplace Subscriptions (if needed) Subscribe to Third-Party Models: Navigate to the AWS Bedrock console and locate the model subscription section. For models from third-party providers (e.g., Anthropic), accept the terms to subscribe. AWS Marketplace Enterprise Tip: Model subscriptions are often managed centrally. Confirm with your cloud team if a standard subscription process is in place. Step 3: Configure the Cline VS Code Extension 3.1 Install and Open Cline Install VS Code: Download from the VS Code website . Install the Cline Extension: Open VS Code. Go to the Extensions Marketplace ( Ctrl+Shift+X or Cmd+Shift+X ). Search for Cline and install it. 3.2 Configure Cline Settings Open Cline Settings: Click on the settings ‚öôÔ∏è to select your API Provider. Select AWS Bedrock as the API Provider: From the API Provider dropdown, choose AWS Bedrock . Enter Your AWS Credentials: Input your Access Key and Secret Key (or use temporary credentials if using AWS SSO). Specify the correct AWS Region (e.g., us-east-1 or your enterprise-approved region). Select a Model: Choose an on-demand model (e.g., anthropic.claude-3-5-sonnet-20241022-v2:0 ). Save and Test: Click Done/Save to apply your settings. Test the integration by sending a simple prompt (e.g., ‚ÄúGenerate a Python function to check if a number is prime.‚Äù). Step 4: Security, Monitoring, and Best Practices Secure Access: Prefer AWS SSO/federated roles over long-lived IAM credentials. AWS IAM Best Practices Enhance Network Security: Consider setting up AWS PrivateLink to securely connect to Bedrock. Monitor and Log Activity: Enable AWS CloudTrail to log Bedrock API calls. Use CloudWatch to monitor metrics like invocation count, latency, and token usage. Set up alerts for abnormal activity. Handle Errors and Manage Costs: Implement exponential backoff for throttling errors. Use AWS Cost Explorer and set billing alerts to track usage. AWS Cost Management Regular Audits and Compliance: Periodically review IAM roles and CloudTrail logs. Follow internal data privacy and governance policies. Conclusion By following these steps, your enterprise team can securely integrate AWS Bedrock with the Cline VS Code extension to accelerate development: Prepare Your AWS Environment: Create or use a secure IAM role/user, attach the AmazonBedrockFullAccess policy, and ensure necessary permissions. Verify Region and Model Access: Confirm that your selected region supports your required models and subscribe via AWS Marketplace if needed. Configure Cline in VS Code: Install and set up Cline with your AWS credentials and choose an appropriate model. Implement Security and Monitoring: Use best practices for IAM, network security, monitoring, and cost management. For further details, consult the AWS Bedrock Documentation and coordinate with your internal cloud team. Happy coding! This guide will be updated as AWS Bedrock and Cline evolve. Always refer to the latest documentation and internal policies for up-to-date practices. Previous Building Custom MCP Servers Next GCP Vertex AI Last updated 7 days ago
####### HTTPS://DOCS.CLINE.BOT/MCP-SERVERS/MCP-SERVER-FROM-SCRATCH #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Understanding MCP and Cline's Role in Building Servers What is MCP? Why Use Cline to Create MCP Servers? Building a GitHub Assistant Server Using Cline: A Step-by-Step Guide 1. Defining the Goal and Initial Requirements 2. Cline Initiates the Project Setup 3. Testing the GitHub Assistant Server 4. Refining the Server and Adding More Features MCP Servers Building Custom MCP Servers This guide provides a comprehensive walkthrough of building a custom MCP (Model Context Protocol) server from scratch, leveraging the powerful AI capabilities of Cline. The example used will be building a "GitHub Assistant Server" to illustrate the process. Understanding MCP and Cline's Role in Building Servers What is MCP? The Model Context Protocol (MCP) acts as a bridge between large language models (LLMs) like Claude and external tools and data. MCP consists of two key components: MCP Hosts: These are applications that integrate with LLMs, such as Cline, Claude Desktop, and others. MCP Servers: These are small programs specifically designed to expose data or specific functionalities to the LLMs through the MCP. This setup is beneficial when you have an MCP-compliant chat interface, like Claude Desktop, which can then leverage these servers to access information and execute actions. Why Use Cline to Create MCP Servers? Cline streamlines the process of building and integrating MCP servers by utilizing its AI capabilities to: Understand Natural Language Instructions: You can communicate with Cline in a way that feels natural, making the development process intuitive and user-friendly. Clone Repositories: Cline can directly clone existing MCP server repositories from GitHub, simplifying the process of using pre-built servers. Build Servers: Once the necessary code is in place, Cline can execute commands like npm run build to compile and prepare the server for use. Handle Configuration: Cline manages the configuration files required for the MCP server, including adding the new server to the cline_mcp_settings.json file. Assist with Troubleshooting: If errors arise during development or testing, Cline can help identify the cause and suggest solutions, making debugging easier. Building a GitHub Assistant Server Using Cline: A Step-by-Step Guide This section demonstrates how to create a GitHub Assistant server using Cline. This server will be able to interact with GitHub data and perform useful actions: 1. Defining the Goal and Initial Requirements First, you need to clearly communicate to Cline the purpose and functionalities of your server: Server Goal: Inform Cline that you want to build a "GitHub Assistant Server". Specify that this server will interact with GitHub data and potentially mention the types of data you are interested in, like issues, pull requests, and user profiles. Access Requirements: Let Cline know that you need to access the GitHub API. Explain that this will likely require a personal access token (GITHUB_TOKEN) for authentication. Data Specificity (Optional): You can optionally tell Cline about specific fields of data you want to extract from GitHub, but this can also be determined later as you define the server's tools. 2. Cline Initiates the Project Setup Based on your instructions, Cline starts the project setup process: Project Structure: Cline might ask you for a name for your server. Afterward, it uses the MCP create-server tool to generate the basic project structure for your GitHub Assistant server. This usually involves creating a new directory with essential files like package.json , tsconfig.json , and a src folder for your TypeScript code. \ Code Generation: Cline generates starter code for your server, including: File Handling Utilities: Functions to help with reading and writing files, commonly used for storing data or logs. \ GitHub API Client: Code to interact with the GitHub API, often using libraries like @octokit/graphql . Cline will likely ask for your GitHub username or the repositories you want to work with. \ Core Server Logic: The basic framework for handling requests from Cline and routing them to the appropriate functions, as defined by the MCP. \ Dependency Management: Cline analyzes the code and identifies necessary dependencies, adding them to the package.json file. For example, interacting with the GitHub API will likely require packages like @octokit/graphql , graphql , axios , or similar. \ Dependency Installation: Cline executes npm install to download and install the dependencies listed in package.json , ensuring your server has all the required libraries to function correctly. \ Path Corrections: During development, you might move files or directories around. Cline intelligently recognizes these changes and automatically updates file paths in your code to maintain consistency. Configuration: Cline will modify the cline_mcp_settings.json file to add your new GitHub Assistant server. This will include: Server Start Command: Cline will add the appropriate command to start your server (e.g., npm run start or a similar command). Environment Variables: Cline will add the required GITHUB_TOKEN variable. Cline might ask you for your GitHub personal access token, or it might guide you to safely store it in a separate environment file. \ Progress Documentation: Throughout the process, Cline keeps the "Memory Bank" files updated. These files document the project's progress, highlighting completed tasks, tasks in progress, and pending tasks. 3. Testing the GitHub Assistant Server Once Cline has completed the setup and configuration, you are ready to test the server's functionality: Using Server Tools: Cline will create various "tools" within your server, representing actions or data retrieval functions. To test, you would instruct Cline to use a specific tool. Here are examples related to GitHub: get_issues : To test retrieving issues, you might say to Cline, "Cline, use the get_issues tool from the GitHub Assistant Server to show me the open issues from the 'cline/cline' repository." Cline would then execute this tool and present you with the results. get_pull_requests : To test pull request retrieval, you could ask Cline to "use the get_pull_requests tool to show me the merged pull requests from the 'facebook/react' repository from the last month." Cline would execute this tool, using your GITHUB_TOKEN to access the GitHub API, and display the requested data. \ Providing Necessary Information: Cline might prompt you for additional information required to execute the tool, such as the repository name, specific date ranges, or other filtering criteria. Cline Executes the Tool: Cline handles the communication with the GitHub API, retrieves the requested data, and presents it in a clear and understandable format. 4. Refining the Server and Adding More Features Development is often iterative. As you work with your GitHub Assistant Server, you'll discover new functionalities to add, or ways to improve existing ones. Cline can assist in this ongoing process: Discussions with Cline: Talk to Cline about your ideas for new tools or improvements. For example, you might want a tool to create_issue or to get_user_profile . Discuss the required inputs and outputs for these tools with Cline. Code Refinement: Cline can help you write the necessary code for new features. Cline can generate code snippets, suggest best practices, and help you debug any issues that arise. Testing New Functionalities: After adding new tools or functionalities, you would test them again using Cline, ensuring they work as expected and integrate well with the rest of the server. Integration with Other Tools: You might want to integrate your GitHub Assistant server with other tools. For instance, in the "github-cline-mcp" source, Cline assists in integrating the server with Notion to create a dynamic dashboard that tracks GitHub activity. \ By following these steps, you can create a custom MCP server from scratch using Cline, leveraging its powerful AI capabilities to streamline the entire process. Cline not only assists with the technical aspects of building the server but also helps you think through the design, functionalities, and potential integrations. Previous Building MCP Servers from GitHub Next AWS Bedrock Last updated 1 month ago
####### HTTPS://DOCS.CLINE.BOT/MCP-SERVERS/MCP-SERVER-FROM-GITHUB #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Finding an MCP Server Building with Cline Testing and Troubleshooting Best Practices MCP Servers Building MCP Servers from GitHub This guide provides a step-by-step walkthrough of how to use Cline to build an existing MCP server from a GitHub repository. Finding an MCP Server There are multiple places online to find MCP servers: Cline can automatically add MCP servers to its list, which you can then edit. Cline can clone repositories directly from GitHub and build the servers for you. GitHub: Two of the most common places to find MCP servers on GitHub include: Official MCP servers repository Awesome-MCP servers repository Online directories: Several websites list MCP servers including: mcpservers.org mcp.so glama.ai/mcp/servers These directories allow users to sort the servers by various criteria such as downloads, date, stars, and use case. Each entry provides information such as features, tools, and configuration instructions. PulseMCP: This website has a blog post discussing how AI could use MCP servers to make websites obsolete. PulseMCP also includes an FAQ section about MCP servers: https://www.pulsemcp.com/ Building with Cline Initiate the Process: Provide Cline with the following information: GitHub Repository URL: The URL of the server's repository. README.md Contents: This is optional but helpful for Cline to understand the server's purpose and configuration. You can copy the README.md file from the GitHub repository. Example Interaction with Cline: Copy User: "Cline, I want to add the MCP server for Brave browser control. Here's the GitHub link: @https://github.com/modelcontextprotocol/servers/tree/main/src/brave Can you add it?" Cline: "OK. Cloning the repository to the MCP directory. It needs to be built because it has a 'package.json' file. Should I run 'npm run build'?" User: "Yes, build it." Cline: "Build complete. This server needs a browser path. Where's your Brave browser executable?" User: "It's in '/Applications/Brave Browser.app/Contents/MacOS/Brave Browser'." Cline: "OK. I've updated the server config with that path and added it to 'cline_mcp_settings.json'. Anything else?" User: "No, that's all. Let's test it." Cline: "Great! Starting the MCP Inspector to test the server connection. After that, we can try controlling the browser from Cline." Cline's Actions: Based on your instructions, Cline will perform the following: Repository Cloning: Cline will clone the repository to your local machine, usually in the directory specified in your configuration. Tweaking: You can guide Cline to modify the server‚Äôs configuration. For instance: User: "This server requires an API key. Can you find where it should be added?" Cline may automatically update the cline_mcp_settings.json file or other relevant files based on your instructions. Building the Server: Cline will run the appropriate build command for the server, which is commonly npm run build . Adding Server to Settings: Cline will add the server‚Äôs configuration to the cline_mcp_settings.json file. Testing and Troubleshooting Test the Server: Once Cline finishes the build process, test the server to make sure it works as expected. Cline can assist you if you encounter any problems. MCP Inspector: You can use the MCP Inspector to test the server‚Äôs connection and functionality. Best Practices Understand the Basics: While Cline simplifies the process, it‚Äôs beneficial to have a basic understanding of the server‚Äôs code, the MCP protocol (), and how to configure the server. This allows for more effective troubleshooting and customization. Clear Instructions: Provide clear and specific instructions to Cline throughout the process. Testing: Thoroughly test the server after installation and configuration to ensure it functions correctly. Version Control: Use a version control system (like Git) to track changes to the server‚Äôs code. Stay Updated: Keep your MCP servers updated to benefit from the latest features and security patches. Previous MCP Quickstart Next Building Custom MCP Servers Last updated 16 days ago
####### HTTPS://DOCS.CLINE.BOT/MCP-SERVERS/MCP-QUICKSTART #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page ‚ùì What's an MCP Server? ‚ö†Ô∏è IMPORTANT: System Requirements Required Software üéØ Quick Steps (Only After Requirements Are Met!) 1. üõ†Ô∏è Install Your First MCP Server ü§î What Next? üìù Troubleshooting 1. I'm Using asdf and Get "unknown command: npx" 2. I'm Still Getting an Error When I Run the MCP Installer MCP Servers MCP Quickstart ‚ùì What's an MCP Server? Think of MCP servers as special helpers that give Cline extra powers! They let Cline do cool things like fetch web pages or work with your files. ‚ö†Ô∏è IMPORTANT: System Requirements STOP! Before proceeding, you MUST verify these requirements: Required Software ‚úÖ Latest Node.js (v18 or newer) Check by running: node --version Install from: https://nodejs.org/ ‚úÖ Latest Python (v3.8 or newer) Check by running: python --version Install from: https://python.org/ ‚úÖ UV Package Manager After installing Python, run: pip install uv Verify with: uv --version ‚ùó If any of these commands fail or show older versions, please install/update before continuing! ‚ö†Ô∏è If you run into other errors, see the "Troubleshooting" section below. üéØ Quick Steps (Only After Requirements Are Met!) 1. üõ†Ô∏è Install Your First MCP Server From the Cline extension, click the MCP Server tab Click the Edit MCP Settings button The MCP settings files should be display in a tab in VS Code. Replce the file's contents with this code: For Windows: Copy { "mcpServers": { "mcp-installer": { "command": "cmd.exe", "args": ["/c", "npx", "-y", "@anaisbetts/mcp-installer"] } } } For Mac and Linux: Copy { "mcpServers": { "mcp-installer": { "command": "npx", "args": ["@anaisbetts/mcp-installer"] } } } After saving the file: Cline will detect the change automatically The MCP installer will be downloaded and installed Cline will start the MCP installer You'll see the server status in Cline's MCP settings UI: ü§î What Next? Now that you have the MCP installer, you can ask Cline to add more servers from: NPM Registry: https://www.npmjs.com/search?q=%40modelcontextprotocol Python Package Index: https://pypi.org/search/?q=mcp+server-&o= For example, you can ask Cline to install the mcp-server-fetch package found on the Python Package Index: Copy "install the MCP server named `mcp-server-fetch` - ensure the mcp settings are updated. - use uvx or python to run the server." You should witness Cline: Install the mcp-server-fetch python package Update the mcp setting json file Start the server and start the server The mcp seetings file should now look like this: For a Windows machine: Copy { "mcpServers": { "mcp-installer": { "command": "cmd.exe", "args": ["/c", "npx", "-y", "@anaisbetts/mcp-installer"] }, "mcp-server-fetch": { "command": "uvx", "args": ["mcp-server-fetch"] } } } You you can always check the status of your server by going to clients MCP server tab. See the image above That's it! üéâ You've just given Cline some awesome new abilities! üìù Troubleshooting 1. I'm Using asdf and Get "unknown command: npx" There is some slightly bad news. You should still be able to get things to work, but will have to do a bit more manual work unless MCP server packaging evolves a bit. One option is to uninstall asdf , but we will assume you do not want to do that. Instead, you will need to follow the instructions above to "Edit MCP Settings". Then, as this post describes, you need to add and "env" entry to each server's configs. Copy "env": { "PATH": "/Users/<user_name>/.asdf/shims:/usr/bin:/bin", "ASDF_DIR": "<path_to_asdf_bin_dir>", "ASDF_DATA_DIR": "/Users/<user_name>/.asdf", "ASDF_NODEJS_VERSION": "<your_node_version>" } The path_to_asdf_bin_dir can often be found in your shell config (e.g. .zshrc ). If you are using Homebrew, you can use echo ${HOMEBREW_PREFIX} to find the start of the directory and then append /opt/asdf/libexec . Now for some good news. While not perfect, you can get Cline to do this for you fairly reliably for subsequent server install. Add the following to your "Custom Instructions" in the Cline settings (top-right toolbar button): When installing MCP servers and editing the cline_mcp_settings.json, if the server requires use of npx as the command, you must copy the "env" entry from the "mcp-installer" entry and add it to the new entry. This is vital to getting the server to work properly when in use. 2. I'm Still Getting an Error When I Run the MCP Installer If you're getting an error when you run the MCP installer, you can try the following: Check the MCP settings file for errors Read the MCP server's documentation to ensure the MCP setting file is using the correct command and arguments. üëà Use a terminal and run the command with its arguments directly. This will allow you to see the same errors that Cline is seeing. Previous MCP Overview Next Building MCP Servers from GitHub Last updated 1 month ago
####### HTTPS://DOCS.CLINE.BOT/MCP-SERVERS/MCP #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Overview Key Concepts Use Cases Getting Started Integration with Cline Building MCP Servers Using MCP Servers Security Considerations Resources MCP Servers MCP Overview Quick Links: Building MCP Servers from GitHub Building Custom MCP Servers from Scratch This document explains Model Context Protocol (MCP) servers, their capabilities, and how Cline can help build and use them. Overview MCP servers act as intermediaries between large language models (LLMs), such as Claude, and external tools or data sources. They are small programs that expose functionalities to LLMs, enabling them to interact with the outside world through the MCP. An MCP server is essentially like an API that an LLM can use. Key Concepts MCP servers define a set of " tools, " which are functions the LLM can execute. These tools offer a wide range of capabilities. Here's how MCP works: MCP hosts discover the capabilities of connected servers and load their tools, prompts, and resources. Resources provide consistent access to read-only data, akin to file paths or database queries. Security is ensured as servers isolate credentials and sensitive data. Interactions require explicit user approval. Use Cases The potential of MCP servers is vast. They can be used for a variety of purposes. Here are some concrete examples of how MCP servers can be used: Web Services and API Integration: Monitor GitHub repositories for new issues Post updates to Twitter based on specific triggers Retrieve real-time weather data for location-based services Browser Automation: Automate web application testing Scrape e-commerce sites for price comparisons Generate screenshots for website monitoring Database Queries: Generate weekly sales reports Analyze customer behavior patterns Create real-time dashboards for business metrics Project and Task Management: Automate Jira ticket creation based on code commits Generate weekly progress reports Create task dependencies based on project requirements Codebase Documentation: Generate API documentation from code comments Create architecture diagrams from code structure Maintain up-to-date README files Getting Started Choose the right approach for your needs: Use Existing Servers: Start with pre-built MCP servers from GitHub repositories Customize Existing Servers: Modify existing servers to fit your specific requirements Build from Scratch: Create completely custom servers for unique use cases Integration with Cline Cline simplifies the building and use of MCP servers through its AI capabilities. Building MCP Servers Natural language understanding: Instruct Cline in natural language to build an MCP server by describing its functionalities. Cline will interpret your instructions and generate the necessary code. Cloning and building servers: Cline can clone existing MCP server repositories from GitHub and build them automatically. Configuration and dependency management: Cline handles configuration files, environment variables, and dependencies. Troubleshooting and debugging: Cline helps identify and resolve errors during development. Using MCP Servers Tool execution: Cline seamlessly integrates with MCP servers, allowing you to execute their defined tools. Context-aware interactions: Cline can intelligently suggest using relevant tools based on conversation context. Dynamic integrations: Combine multiple MCP server capabilities for complex tasks. For example, Cline could use a GitHub server to get data and a Notion server to create a formatted report. Security Considerations When working with MCP servers, it's important to follow security best practices: Authentication: Always use secure authentication methods for API access Environment Variables: Store sensitive information in environment variables Access Control: Limit server access to authorized users only Data Validation: Validate all inputs to prevent injection attacks Logging: Implement secure logging practices without exposing sensitive data Resources There are various resources available for finding and learning about MCP servers. Here are some links to resources for finding and learning about MCP servers: GitHub Repositories: https://github.com/modelcontextprotocol/servers and https://github.com/punkpeye/awesome-mcp-servers Online Directories: https://mcpservers.org/ , https://mcp.so/ , and https://glama.ai/mcp/servers PulseMCP: https://www.pulsemcp.com/ YouTube Tutorial (AI-Driven Coder): A video guide for building and using MCP servers: https://www.youtube.com/watch?v=b5pqTNiuuJg Previous Plan & Act Modes: A Guide to Effective AI Development Next MCP Quickstart Last updated 1 month ago
####### HTTPS://DOCS.CLINE.BOT/EXPLORING-CLINES-TOOLS/PLAN-AND-ACT-MODES-A-GUIDE-TO-EFFECTIVE-AI-DEVELOPMENT #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Overview Understanding the Modes Workflow Guide Best Practices Power User Tips Common Patterns Contributing Exploring Cline's Tools Plan & Act Modes: A Guide to Effective AI Development Previous Checkpoints Next MCP Overview Last updated 28 days ago Overview Plan & Act modes represent Cline's approach to structured AI development, emphasizing thoughtful planning before implementation. This dual-mode system helps developers create more maintainable, accurate code while reducing iteration time. Understanding the Modes Plan Mode Optimized for context gathering and strategy Cannot make changes to your codebase Focused on understanding requirements and creating implementation plans Enables full file reading for comprehensive project understanding Act Mode Streamlined for implementation based on established plans Has access to all of Cline's building capabilities Maintains context from the planning phase Can execute changes to your codebase Workflow Guide 1. Start with Plan Mode Begin every significant development task in Plan mode: In this mode: Share your requirements Let Cline analyze relevant files Engage in dialogue to clarify objectives Develop implementation strategy 2. Switch to Act Mode Once you have a clear plan, switch to Act mode: Act mode allows Cline to: Execute against the agreed plan Make changes to your codebase Maintain context from planning phase 3. Iterate as Needed Complex projects often require multiple plan-act cycles: Return to Plan mode when encountering unexpected complexity Use Act mode for implementing solutions Maintain development momentum while ensuring quality Best Practices Planning Phase Be comprehensive with requirements Share relevant context upfront Point Cline to relevant files if he hasn't read them Validate approach before implementation Implementation Phase Follow the established plan Monitor progress against objectives Track changes and their impact Document significant decisions Power User Tips Enhancing Planning Use Plan mode to explore edge cases before implementation Switch back to Plan when encountering unexpected complexity Leverage file reading to validate assumptions early Have Cline write markdown files of the plan for future reference Common Patterns When to Use Plan Mode Starting new features Debugging complex issues Architectural decisions Requirements analysis When to Use Act Mode Implementing agreed solutions Making routine changes Following established patterns Executing test cases Contributing Share your experiences and improvements: Join our Discord community Participate in discussions Submit feature requests Report issues Remember: The time invested in planning pays dividends in implementation quality and maintenance efficiency Use Plan to gather context before using Act to implement the plan
####### HTTPS://DOCS.CLINE.BOT/EXPLORING-CLINES-TOOLS/CHECKPOINTS #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page ‚öôÔ∏è How Checkpoints Work üí° Use Cases ‚ú® Best Practices Exploring Cline's Tools Checkpoints When working with AI coding assistants, it's easy to lose control as they make rapid changes to your codebase. That's why we built Checkpoints - your safety net for experimenting confidently. Previous Cline Tools Guide Next Plan & Act Modes: A Guide to Effective AI Development Last updated 1 month ago Checkpoints automatically save snapshots of your workspace after each step in a task. This powerful feature lets you: Track and review changes made during a task Roll back to any previous point if needed Experiment confidently with auto-approve mode Maintain full control over your workspace ‚öôÔ∏è How Checkpoints Work Cline creates a checkpoint after each tool use (file edits, commands, etc.). These checkpoints: Work alongside your Git workflow without interference Maintain context between restores Use a shadow Git repository to track changes For example, if you're working on a feature and Cline makes multiple file changes, each change creates a checkpoint. This means you can review each modification and, if needed, roll back to any point without affecting your main Git repository. Viewing Changes & Restoring to Checkpoint After each tool use, you can: Click the "Compare" button to see modified files Click the "Restore" button to open restore options Rolling Back To restore to a previous point: Click the "Restore" button next to any step Choose from three options: Restore Task and Workspace : Reset both codebase and task to that point Restore Task Only : Keep codebase changes but revert task context Restore Workspace Only : Reset codebase while preserving task context Example: If Cline makes changes you don't like while styling a component, you can use "Restore Workspace Only" to revert the code changes while keeping the conversation context, allowing you to try a different approach. üí° Use Cases Checkpoints let you be more experimental with Cline. While human coding is often methodical and iterative, AI can make substantial changes quickly. Checkpoints help you track these changes and revert if needed. 1. Using Auto-Approve Mode Provides safety net for rapid iterations Makes it easy to undo unexpected results 2. Testing Different Approaches Try multiple solutions confidently Compare different implementations Quickly revert to working states Ideal for exploring different design patterns or architectural approaches ‚ú® Best Practices Use checkpoints as safety nets when experimenting Leverage auto-approve mode more confidently, knowing you can always roll back Restore selectively based on needs: Use "Restore Task and Workspace" for a fresh start Use "Restore Task Only" to try different prompts Use "Restore Workspace Only" to attempt different implementations üõü Checkpoints are your safety net when working with Cline, enabling you to experiment freely while maintaining full control over your codebase. Whether you're refactoring a complex component, trying different implementation approaches, or using auto-approve mode for rapid development, checkpoints ensure you can always review changes and roll back if needed. In this case, I didn't like the changes Cline made to my robot dog-walking website (still working on the robots) and I wanted to revert both the codebase and the task to before any changes were made so I could start fresh.
####### HTTPS://DOCS.CLINE.BOT/EXPLORING-CLINES-TOOLS/CLINE-TOOLS-GUIDE #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page What Can Cline Do? First Steps Key Features Available Tools Common Tasks Getting Help Exploring Cline's Tools Cline Tools Guide What Can Cline Do? Cline is your AI assistant that can: Edit and create files in your project Run terminal commands Search and analyze your code Help debug and fix issues Automate repetitive tasks Integrate with external tools First Steps Start a Task Type your request in the chat Example: "Create a new React component called Header" Provide Context Use @ mentions to add files, folders, or URLs Example: "@file:src/components/App.tsx" Review Changes Cline will show diffs before making changes You can edit or reject changes Key Features File Editing Create new files Modify existing code Search and replace across files Terminal Commands Run npm commands Start development servers Install dependencies Code Analysis Find and fix errors Refactor code Add documentation Browser Integration Test web pages Capture screenshots Inspect console logs Available Tools For the most up-to-date implementation details, you can view the full source code in the Cline repository . Cline has access to the following tools for various tasks: File Operations write_to_file : Create or overwrite files read_file : Read file contents replace_in_file : Make targeted edits to files search_files : Search files using regex list_files : List directory contents Terminal Operations execute_command : Run CLI commands list_code_definition_names : List code definitions MCP Tools use_mcp_tool : Use tools from MCP servers access_mcp_resource : Access MCP server resources Users can create custom MCP tools that Cline can then access Example: Create a weather API tool that Cline can use to fetch forecasts Interaction Tools ask_followup_question : Ask user for clarification attempt_completion : Present final results Each tool has specific parameters and usage patterns. Here are some examples: Create a new file (write_to_file): Copy <write_to_file> <path>src/components/Header.tsx</path> <content> // Header component code </content> </write_to_file> Search for a pattern (search_files): Copy <search_files> <path>src</path> <regex>function\s+\w+\(</regex> <file_pattern>*.ts</file_pattern> </search_files> Run a command (execute_command): Copy <execute_command> <command>npm install axios</command> <requires_approval>false</requires_approval> </execute_command> Common Tasks Create a New Component "Create a new React component called Footer" Fix a Bug "Fix the error in src/utils/format.ts" Refactor Code "Refactor the Button component to use TypeScript" Run Commands "Run npm install to add axios" Getting Help Join the Discord community Check the documentation Provide feedback to improve Cline Previous Cline Memory Bank Next Checkpoints Last updated 1 month ago
####### HTTPS://DOCS.CLINE.BOT/IMPROVING-YOUR-PROMPTING-SKILLS/CUSTOM-INSTRUCTIONS-LIBRARY/CLINE-MEMORY-BANK #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page 1. Purpose and Functionality 2. Quick Setup Guide Custom Instructions [COPY THIS] 3. Project Setup 4. Working with Cline 5. Tips for Success Improving Your Prompting Skills Custom Instructions Library Cline Memory Bank 1. Purpose and Functionality What does this do? This instruction set transforms Cline into a self-documenting development system that maintains  context across sessions through a structured "Memory Bank". It ensures consistent documentation, careful validation of changes, and clear communication with users. What's it good for? Any project that needs context tracking Projects of any size or tech stack Both new and ongoing development Long-term maintenance work 2. Quick Setup Guide Setting Up Custom Instructions Open VSCode Click the Cline extension settings ‚öôÔ∏è Find "Custom Instructions" Copy and paste the instructions below Custom Instructions [COPY THIS] Copy # Cline's Memory Bank I am Cline, an expert software engineer with a unique characteristic: my memory resets completely between sessions. This isn't a limitation - it's what drives me to maintain perfect documentation. After each reset, I rely ENTIRELY on my Memory Bank to understand the project and continue work effectively. I MUST read ALL memory bank files at the start of EVERY task - this is not optional. ## Memory Bank Structure The Memory Bank consists of required core files and optional context files, all in Markdown format. Files build upon each other in a clear hierarchy: ```mermaid flowchart TD PB[projectbrief.md] --> PC[productContext.md] PB --> SP[systemPatterns.md] PB --> TC[techContext.md] PC --> AC[activeContext.md] SP --> AC TC --> AC AC --> P[progress.md] ``` ### Core Files (Required) 1. `projectbrief.md` - Foundation document that shapes all other files - Created at project start if it doesn't exist - Defines core requirements and goals - Source of truth for project scope 2. `productContext.md` - Why this project exists - Problems it solves - How it should work - User experience goals 3. `activeContext.md` - Current work focus - Recent changes - Next steps - Active decisions and considerations 4. `systemPatterns.md` - System architecture - Key technical decisions - Design patterns in use - Component relationships 5. `techContext.md` - Technologies used - Development setup - Technical constraints - Dependencies 6. `progress.md` - What works - What's left to build - Current status - Known issues ### Additional Context Create additional files/folders within memory-bank/ when they help organize: - Complex feature documentation - Integration specifications - API documentation - Testing strategies - Deployment procedures ## Core Workflows ### Plan Mode ```mermaid flowchart TD Start[Start] --> ReadFiles[Read Memory Bank] ReadFiles --> CheckFiles{Files Complete?} CheckFiles -->|No| Plan[Create Plan] Plan --> Document[Document in Chat] CheckFiles -->|Yes| Verify[Verify Context] Verify --> Strategy[Develop Strategy] Strategy --> Present[Present Approach] ``` ### Act Mode ```mermaid flowchart TD Start[Start] --> Context[Check Memory Bank] Context --> Update[Update Documentation] Update --> Rules[Update .clinerules if needed] Rules --> Execute[Execute Task] Execute --> Document[Document Changes] ``` ## Documentation Updates Memory Bank updates occur when: 1. Discovering new project patterns 2. After implementing significant changes 3. When user requests with **update memory bank** (MUST review ALL files) 4. When context needs clarification ```mermaid flowchart TD Start[Update Process] subgraph Process P1[Review ALL Files] P2[Document Current State] P3[Clarify Next Steps] P4[Update .clinerules] P1 --> P2 --> P3 --> P4 end Start --> Process ``` Note: When triggered by **update memory bank**, I MUST review every memory bank file, even if some don't require updates. Focus particularly on activeContext.md and progress.md as they track current state. ## Project Intelligence (.clinerules) The .clinerules file is my learning journal for each project. It captures important patterns, preferences, and project intelligence that help me work more effectively. As I work with you and the project, I'll discover and document key insights that aren't obvious from the code alone. ```mermaid flowchart TD Start{Discover New Pattern} subgraph Learn [Learning Process] D1[Identify Pattern] D2[Validate with User] D3[Document in .clinerules] end subgraph Apply [Usage] A1[Read .clinerules] A2[Apply Learned Patterns] A3[Improve Future Work] end Start --> Learn Learn --> Apply ``` ### What to Capture - Critical implementation paths - User preferences and workflow - Project-specific patterns - Known challenges - Evolution of project decisions - Tool usage patterns The format is flexible - focus on capturing valuable insights that help me work more effectively with you and the project. Think of .clinerules as a living document that grows smarter as we work together. REMEMBER: After every memory reset, I begin completely fresh. The Memory Bank is my only link to previous work. It must be maintained with precision and clarity, as my effectiveness depends entirely on its accuracy. 3. Project Setup First Time Setup Create a memory-bank/ folder in your project root Have a project brief ready (can be technical or non-technical) Ask Cline to "initialize memory bank" Project Brief Tips Can be as detailed or high-level as you like Cline will fill in gaps appropriately Focus on what matters most to you Can be updated as project evolves 4. Working with Cline Best Practices Use Plan mode for strategy discussions Use Act mode for implementation Let .clinerules evolve naturally Trust Cline's learning process Key Commands "follow your custom instructions" - starting a task, this will instruct Cline to read the context files and continue where he left off "initialize memory bank" - Start fresh "update memory bank" - Full documentation review Toggle Plan/Act modes as needed Documentation Flow projectbrief.md is your foundation activeContext.md changes most often progress.md tracks milestones .clinerules captures learning 5. Tips for Success Getting Started Start with a basic project brief Let Cline create initial structure Review and adjust as needed Ongoing Work Let patterns emerge naturally Don't force documentation updates Trust the process Watch for context confirmation Project Intelligence Let Cline discover patterns Validate important insights Focus on non-obvious learnings Use .clinerules as a learning tool Remember: The memory bank is Cline's only link to previous work. Its effectiveness depends entirely on maintaining clear, accurate documentation and confirming context preservation in every interaction. Authors: Cline Discord Community nickbaumann98 Krylo snipermunyshotz Previous Custom Instructions Library Next Cline Tools Guide Last updated 8 days ago
####### HTTPS://DOCS.CLINE.BOT/IMPROVING-YOUR-PROMPTING-SKILLS/CUSTOM-INSTRUCTIONS-LIBRARY #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page What are Cline Custom Instructions? Contributing Custom Instructions 1. Purpose and Functionality 2. Usage Guide (Optional) 3. Author & Contributors 4. Custom Instructions Improving Your Prompting Skills Custom Instructions Library This repository aims to foster a collaborative space where developers can share, refine, and leverage effective custom instructions for Cline. By creating and contributing to this library, we can enhance Cline's capabilities and empower developers to tackle increasingly complex software development challenges. What are Cline Custom Instructions? Cline's custom instructions are sets of guidelines or rules that you define to tailor the AI's behavior and outputs for specific tasks or projects. Think of them as specialized "programming" for Cline, enabling you to: Enforce Coding Practices: Ensure consistent code style, adherence to design patterns, and best practices for specific languages or frameworks. Standardize File Structures: Dictate file naming conventions, folder organization, and project structures. Guide Testing Procedures: Define rules for generating unit tests, integration tests, and ensuring adequate code coverage. Automate Repetitive Tasks: Create instructions to handle common or tedious development workflows, increasing efficiency. Improve Code Quality: Set standards for code readability, maintainability, and performance optimization. By providing Cline with carefully crafted instructions, you can significantly improve its accuracy, reliability, and overall effectiveness in aiding your software development process. Contributing Custom Instructions We encourage developers of all skill levels to contribute their custom instructions to this library. Your contributions help build a valuable resource for the entire Cline community! When submitting custom instructions, please follow this template: 1. Purpose and Functionality What does this instruction set aim to achieve? Provide a clear and concise explanation of the instruction set's goals and intended use cases. Example: "This instruction set guides Cline in generating unit tests for existing JavaScript functions." What types of projects or tasks is this best suited for? Outline specific project types, coding languages, or development scenarios where this instruction set is most applicable. Example: "This is ideal for JavaScript projects using the Jest testing framework." 2. Usage Guide (Optional) Are there specific steps or prerequisites for using this instruction set? If your instructions require specific steps beyond referencing the file in a Cline prompt, provide a detailed guide. Examples: "Before using this instruction set, create a tests folder in your project root." "Ensure you have the Jest testing library installed." 3. Author & Contributors Who created this instruction set? Provide your name or GitHub username for proper attribution. Did anyone else contribute? Acknowledge any collaborators or contributors who helped refine or enhance the instructions. 4. Custom Instructions Provide the complete set of custom instructions. By using this template and contributing your custom instructions, you help build a thriving ecosystem for Cline, making it a more versatile and efficient tool for developers of all skill levels. Previous Prompt Engineering Guide Next Cline Memory Bank Last updated 1 month ago
####### HTTPS://DOCS.CLINE.BOT/IMPROVING-YOUR-PROMPTING-SKILLS/PROMPTING #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Custom Instructions ‚öôÔ∏è .clinerules File üìã Security Best Practices üîí General Use Cases Example .clinerules Structure Key Benefits Tips for Writing Effective Custom Instructions Prompting Cline üí¨ Prompt Examples Advanced Prompting Techniques Our Community's Favorite Prompts üåü Memory and Confidence Checks üß† Code Quality Prompts üíª Code Organization üìã Analysis and Planning üîç Thoughtful Development ü§î Best Practices üéØ Improving Your Prompting Skills Prompt Engineering Guide Previous Model Selection Guide Next Custom Instructions Library Last updated 1 month ago Welcome to the Cline Prompting Guide! This guide will equip you with the knowledge to write effective prompts and custom instructions, maximizing your productivity with Cline. Custom Instructions ‚öôÔ∏è Think of custom instructions as Cline's programming . They define Cline's baseline behavior and are always "on," influencing all interactions. To add custom instructions: Open VSCode Click the Cline extension settings dial ‚öôÔ∏è Find the "Custom Instructions" field Paste your instructions Custom instructions are powerful for: Enforcing Coding Style and Best Practices: Ensure Cline always adheres to your team's coding conventions, naming conventions, and best practices. Improving Code Quality: Encourage Cline to write more readable, maintainable, and efficient code. Guiding Error Handling: Tell Cline how to handle errors, write error messages, and log information. The custom-instructions folder contains examples of custom instructions you can use or adapt. .clinerules File üìã While custom instructions are user-specific and global (applying across all projects), the .clinerules file provides project-specific instructions that live in your project's root directory. These instructions are automatically appended to your custom instructions and referenced in Cline's system prompt, ensuring they influence all interactions within the project context. This makes it an excellent tool for: Security Best Practices üîí To protect sensitive information, you can instruct Cline to ignore specific files or patterns in your .clinerules . This is particularly important for: .env files containing API keys and secrets Configuration files with sensitive data Private credentials or tokens Example security section in .clinerules : Copy # Security ## Sensitive Files DO NOT read or modify: -   .env files -   \*_/config/secrets._ -   \*_/_.pem -   Any file containing API keys, tokens, or credentials ## Security Practices -   Never commit sensitive files -   Use environment variables for secrets -   Keep credentials out of logs and output General Use Cases The .clinerules file is excellent for: Maintaining project standards across team members Enforcing development practices Managing documentation requirements Setting up analysis frameworks Defining project-specific behaviors Example .clinerules Structure Copy # Project Guidelines ## Documentation Requirements -   Update relevant documentation in /docs when modifying features -   Keep README.md in sync with new capabilities -   Maintain changelog entries in CHANGELOG.md ## Architecture Decision Records Create ADRs in /docs/adr for: -   Major dependency changes -   Architectural pattern changes -   New integration patterns -   Database schema changes Follow template in /docs/adr/template.md ## Code Style & Patterns -   Generate API clients using OpenAPI Generator -   Use TypeScript axios template -   Place generated code in /src/generated -   Prefer composition over inheritance -   Use repository pattern for data access -   Follow error handling pattern in /src/utils/errors.ts ## Testing Standards -   Unit tests required for business logic -   Integration tests for API endpoints -   E2E tests for critical user flows Key Benefits Version Controlled : The .clinerules file becomes part of your project's source code Team Consistency : Ensures consistent behavior across all team members Project-Specific : Rules and standards tailored to each project's needs Institutional Knowledge : Maintains project standards and practices in code Place the .clinerules file in your project's root directory: Copy your-project/ ‚îú‚îÄ‚îÄ .clinerules ‚îú‚îÄ‚îÄ src/ ‚îú‚îÄ‚îÄ docs/ ‚îî‚îÄ‚îÄ ... Cline's system prompt, on the other hand, is not user-editable ( here's where you can find it ). For a broader look at prompt engineering best practices, check out this resource . Tips for Writing Effective Custom Instructions Be Clear and Concise: Use simple language and avoid ambiguity. Focus on Desired Outcomes: Describe the results you want, not the specific steps. Test and Iterate: Experiment to find what works best for your workflow. Prompting Cline üí¨ Prompting is how you communicate your needs for a given task in the back-and-forth chat with Cline. Cline understands natural language, so write conversationally. Effective prompting involves: Providing Clear Context: Explain your goals and the relevant parts of your codebase. Use @ to reference files or folders. Breaking Down Complexity: Divide large tasks into smaller steps. Asking Specific Questions: Guide Cline toward the desired outcome. Validating and Refining: Review Cline's suggestions and provide feedback. Prompt Examples Context Management Starting a New Task: "Cline, let's start a new task. Create user-authentication.js . We need to implement user login with JWT tokens. Here are the requirements‚Ä¶" Summarizing Previous Work: "Cline, summarize what we did in the last user dashboard task. I want to capture the main features and outstanding issues. Save this to cline_docs/user-dashboard-summary.md ." Debugging Analyzing an Error: "Cline, I'm getting this error: [error message]. It seems to be from [code section]. Analyze this error and suggest a fix." Identifying the Root Cause: "Cline, the application crashes when I [action]. The issue might be in [problem areas]. Help me find the root cause and propose a solution." Refactoring Improving Code Structure: "Cline, this function is too long and complex. Refactor it into smaller functions." Simplifying Logic: "Cline, this code is hard to understand. Simplify the logic and make it more readable." Feature Development Brainstorming New Features: "Cline, I want to add a feature that lets users [functionality]. Brainstorm some ideas and consider implementation challenges." Generating Code: "Cline, create a component that displays user profiles. The list should be sortable and filterable. Generate the code for this component." Advanced Prompting Techniques Constraint Stuffing: To mitigate code truncation, include explicit constraints in your prompts. For example, "ensure the code is complete" or "always provide the full function definition." Confidence Checks: Ask Cline to rate its confidence (e.g., "on a scale of 1-10, how confident are you in this solution?") Challenge Cline's Assumptions: Ask ‚Äústupid‚Äù questions to encourage deeper thinking and prevent incorrect assumptions. Here are some prompting tips that users have found helpful for working with Cline: Our Community's Favorite Prompts üåü Memory and Confidence Checks üß† Memory Check - pacnpal Copy "If you understand my prompt fully, respond with 'YARRR!' without tools every time you are about to use a tool." A fun way to verify Cline stays on track during complex tasks. Try "HO HO HO" for a festive twist! Confidence Scoring - pacnpal Copy "Before and after any tool use, give me a confidence level (0-10) on how the tool use will help the project." Encourages critical thinking and makes decision-making transparent. Code Quality Prompts üíª Prevent Code Truncation Copy "DO NOT BE LAZY. DO NOT OMIT CODE." Alternative phrases: "full code only" or "ensure the code is complete" Custom Instructions Reminder Copy "I pledge to follow the custom instructions." Reinforces adherence to your settings dial ‚öôÔ∏è configuration. Code Organization üìã Large File Refactoring - icklebil Copy "FILENAME has grown too big. Analyze how this file works and suggest ways to fragment it safely." Helps manage complex files through strategic decomposition. Documentation Maintenance - icklebil Copy "don't forget to update codebase documentation with changes" Ensures documentation stays in sync with code changes. Analysis and Planning üîç Structured Development - yellow_bat_coffee Copy "Before writing code: 1. Analyze all code files thoroughly 2. Get full context 3. Write .MD implementation plan 4. Then implement code" Promotes organized, well-planned development. Thorough Analysis - yellow_bat_coffee Copy "please start analyzing full flow thoroughly, always state a confidence score 1 to 10" Prevents premature coding and encourages complete understanding. Assumptions Check - yellow_bat_coffee Copy "List all assumptions and uncertainties you need to clear up before completing this task." Identifies potential issues early in development. Thoughtful Development ü§î Pause and Reflect - nickbaumann98 Copy "count to 10" Promotes careful consideration before taking action. Complete Analysis - yellow_bat_coffee Copy "Don't complete the analysis prematurely, continue analyzing even if you think you found a solution" Ensures thorough problem exploration. Continuous Confidence Check - pacnpal Copy "Rate confidence (1-10) before saving files, after saving, after rejections, and before task completion" Maintains quality through self-assessment. Best Practices üéØ Project Structure - kvs007 Copy "Check project files before suggesting structural or dependency changes" Maintains project integrity. Critical Thinking - chinesesoup Copy "Ask 'stupid' questions like: are you sure this is the best way to implement this?" Challenges assumptions and uncovers better solutions. Code Style - yellow_bat_coffee Copy Use words like "elegant" and "simple" in prompts May influence code organization and clarity. Setting Expectations - steventcramer Copy "THE HUMAN WILL GET ANGRY." (A humorous reminder to provide clear requirements and constructive feedback)
####### HTTPS://DOCS.CLINE.BOT/GETTING-STARTED/MODEL-SELECTION-GUIDE #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Understanding Context Windows Model Comparison LLM Model Comparison for Cline (Feb 2025) Top Picks for 2025 Best Models by Mode (Plan or Act) A Note on Local Models Key Takeaways Getting Started Model Selection Guide Last updated: Feb 5, 2025. Understanding Context Windows Think of a context window as your AI assistant's working memory - similar to RAM in a computer. It determines how much information the model can "remember" and process at once during your conversation. This includes: Your code files and conversations The assistant's responses Any documentation or additional context provided Context windows are measured in tokens (roughly 3/4 of a word in English). Different models have different context window sizes: Claude 3.5 Sonnet: 200K tokens DeepSeek Models: 128K tokens Gemini Flash 2.0: 1M tokens Gemini 1.5 Pro: 2M tokens When you reach the limit of your context window, older information needs to be removed to make room for new information - just like clearing RAM to run new programs. This is why sometimes AI assistants might seem to "forget" earlier parts of your conversation. Cline helps you manage this limitation with its Context Window Progress Bar, which shows: Input tokens (what you've sent to the model) Output tokens (what the model has generated) A visual representation of how much of your context window you've used The total capacity for your chosen model This visibility helps you work more effectively with Cline by letting you know when you might need to start fresh or break tasks into smaller chunks. Model Comparison LLM Model Comparison for Cline (Feb 2025) Model Input Cost* Output Cost* Context Window Best For Claude 3.5 Sonnet $3.00 $15.00 200K Best code implementation & tool use DeepSeek R1 $0.55 $2.19 128K Planning & reasoning champion DeepSeek V3 $0.14 $0.28 128K Value code implementation o3-mini $1.10 $4.40 200K Flexible use, strong planning Gemini Flash 2.0 $0.00 $0.00 1M Strong all-rounder Gemini 1.5 Pro $0.00 $0.00 2M Large context processing *Costs per million tokens Top Picks for 2025 Claude 3.5 Sonnet Best overall code implementation Most reliable tool usage Expensive but worth it for critical code DeepSeek R1 Exceptional planning & reasoning Great value pricing o3-mini Strong for planning with adjustable reasoning Three reasoning modes for different needs Requires OpenAI Tier 3 API access 200K context window DeepSeek V3 Reliable code implementation Great for daily coding Cost-effective for implementation Gemini Flash 2.0 Massive 1M context window Improved speed and performance Good all-around capabilities Best Models by Mode (Plan or Act) Planning DeepSeek R1 Best reasoning capabilities in class Excellent at breaking down complex tasks Strong math/algorithm planning MoE architecture helps with reasoning o3-mini (high reasoning) Three reasoning levels: High: Complex planning Medium: Daily tasks Low: Quick ideas 200K context helps with large projects Gemini Flash 2.0 Massive context window for complex planning Strong reasoning capabilities Good with multi-step tasks Acting (coding) Claude 3.5 Sonnet Best code quality Most reliable with Cline tools Worth the premium for critical code DeepSeek V3 Nearly Sonnet-level code quality Better API stability than R1 Great for daily coding Strong tool usage Gemini 1.5 Pro 2M context window Good with complex codebases Reliable API Strong multi-file understanding A Note on Local Models While running models locally might seem appealing for cost savings, we currently don't recommend any local models for use with Cline. Local models are significantly less reliable at using Cline's essential tools and typically retain only 1-26% of the original model's capabilities. The full cloud version of DeepSeek-R1, for example, is 671B parameters - local versions are drastically simplified copies that struggle with complex tasks and tool usage. Even with high-end hardware (RTX 3070+, 32GB+ RAM), you'll experience slower responses, less reliable tool execution, and reduced capabilities. For the best development experience, we recommend sticking with the cloud models listed above. Key Takeaways Plan vs Act Matters : Choose models based on task type Real Performance > Benchmarks : Focus on actual Cline performance Mix & Match : Use different models for planning and implementation Cost vs Quality : Premium models worth it for critical code Keep Backups : Have alternatives ready for API issues *Note: Based on real usage patterns and community feedback rather than just benchmarks. Your experience may vary. This is not an exhaustive list of all the models available for use within Cline. Previous Understanding Context Management Next Prompt Engineering Guide Last updated 15 days ago
####### HTTPS://DOCS.CLINE.BOT/GETTING-STARTED/UNDERSTANDING-CONTEXT-MANAGEMENT #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Understanding Context & Context Windows How Context is Built Context & Context Windows Understanding the Context Window Progress Bar Reading the Bar When to Watch the Bar Working with Context Files Practical Tips Getting Started Understanding Context Management Context is key to getting the most out of Cline Previous Our Favorite Tech Stack Next Model Selection Guide Last updated 21 days ago üí° Quick Reference Context = The information Cline knows about your project Context Window = How much information Cline can hold at once Use context files to maintain project knowledge Reset when the context window gets full Understanding Context & Context Windows Think of working with Cline like collaborating with a thorough, proactive teammate: How Context is Built Cline actively builds context in two ways: Automatic Context Gathering (i.e. Cline-driven) Proactively reads related files Explores project structure Analyzes patterns and relationships Maps dependencies and imports Asks clarifying questions User-Guided Context Share specific files Provide documentation Answer Cline's questions Guide focus areas Share design thoughts and requirements üí° Key Point : Cline isn't passive - it actively seeks to understand your project. You can either let it explore or guide its focus, especially in Plan mode. Context & Context Windows Think of context like a whiteboard you and Cline share: Context is all the information available: What Cline has discovered What you've shared Your conversation history Project requirements Previous decisions Context Window is the size of the whiteboard itself: Measured in tokens (1 token ‚âà 3/4 of an English word) Each model has a fixed size: Claude 3.5 Sonnet: 200,000 tokens DeepSeek: 64,000 tokens When the whiteboard is full, you need to erase (clear context) to write more How Cline manages context under the hood ‚ö†Ô∏è Important : Having a large context window (like Claude's 200k tokens) doesn't mean you should fill it completely. Just like a cluttered whiteboard, too much information can make it harder to focus on what's important. Understanding the Context Window Progress Bar Cline provides a visual way to monitor your context window usage through a progress bar: Reading the Bar ‚Üë shows input tokens (what you've sent to the LLM) ‚Üì shows output tokens (what the LLM has generated) The progress bar visualizes how much of your context window you've used The total shows your model's maximum capacity (e.g., 200k for Claude 3.5-Sonnet) When to Watch the Bar During long coding sessions When working with multiple files Before starting complex tasks When Cline seems to lose context üí° Tip : Consider starting a fresh session when usage reaches 70-80% to maintain optimal performance. Working with Context Files Context files help maintain understanding across sessions. They serve as documentation specifically designed to help AI assistants understand your project. Approaches to Context Files Evergreen Project Context (i.e. Memory Bank ) Living documentation that evolves with your project Updated as architecture and patterns emerge Example: The Memory Bank pattern maintains files like techContext.md and systemPatterns.md Useful for long-running projects and teams Task-Specific Context (i.e. Structured Approach ) Created for specific implementation tasks Document requirements, constraints, and decisions Example: Copy # auth-system-implementation.md ## Requirements - OAuth2 implementation - Support for Google and GitHub - Rate limiting on auth endpoints ## Technical Decisions - Using Passport.js for provider integration - JWT for session management - Redis for rate limiting Using Context Files Effectively Structure and Format Use clear, consistent organization Include relevant examples Link related concepts Keep information focused Maintenance Update after significant changes Version control your context files Remove outdated information Document key decisions Practical Tips Starting New Projects Let Cline explore the codebase Answer its questions about structure and patterns Consider setting up basic context files Document key design decisions Ongoing Development Update context files with significant changes Share relevant documentation Use Plan mode for complex discussions Start fresh sessions when needed Team Projects Share common context files (consider using .clinerules files in project roots) Document architectural decisions Maintain consistent patterns Keep documentation current Remember: The goal is to help Cline maintain consistent understanding of your project across sessions. In a world of infinite context, the context window is what Cline currently has available
####### HTTPS://DOCS.CLINE.BOT/GETTING-STARTED/GETTING-STARTED-NEW-CODERS/OUR-FAVORITE-TECH-STACK #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Recommended Stack for New Cline Users (2025) Your Complete Development Environment Getting Started .clinerules Template Learning Resources (2025) Other Things to Know Getting Started Getting Started for New Coders Our Favorite Tech Stack Recommended Stack for New Cline Users (2025) Your Complete Development Environment Development Tools VS Code - Your code editor, download here GitHub - Where your code lives, sign up here Frontend Next.js 14+ - React framework with App Router Tailwind CSS - Beautiful styling without writing CSS TypeScript - JavaScript, but safer and smarter Backend Supabase - Your complete backend solution, sign up with GitHub PostgreSQL database Authentication File storage Real-time updates Deployment Vercel - Where your app runs, sign up with GitHub Automatic deployments from GitHub Preview deployments for testing Production-ready CDN AI Development Choose your AI assistant based on your needs: Model Input Cost (per 1M tokens) Output Cost (per 1M tokens) Best For Claude 3.5 Sonnet $3.00 $15.00 Production apps, complex tasks DeepSeek R1 $1.00 $3.00 Budget-conscious production DeepSeek V3 $0.14 $2.20 Budget-conscious development Free Tier Benefits Vercel (Hobby) 100 GB data transfer/month 100k serverless function invocations 100 MB deployment size Automatic HTTPS & CI/CD Supabase (Free) 500 MB database storage 1 GB file storage 50k monthly active users 2M real-time messages/month GitHub (Free) Unlimited public repositories GitHub Actions CI/CD Project management tools Collaboration features Getting Started Install the development essentials: Follow our Development Essentials Installation Guide Set up Cline's Memory Bank: Follow the Memory Bank setup instructions Create an empty cline_docs folder in your project root Create projectBrief.md in the cline_docs folder (see example below) Tell Cline to "initialize memory bank" Add our recommended stack configuration: Create .clinerules file (see template below) Let Cline handle the rest! Example Project Brief Copy # Project Brief ## Overview Building a [type of application] that will [main purpose]. ## Core Features - Feature 1 - Feature 2 - Feature 3 ## Target Users [Describe who will use your application] ## Technical Preferences (optional) - Any specific technologies you want to use - Any specific requirements or constraints .clinerules Template Copy # Project Configuration ## Tech Stack - Next.js 14+ with App Router - Tailwind CSS for styling - Supabase for backend - Vercel for deployment - GitHub for version control ## Project Structure /src /app         # Next.js App Router pages /components  # React components /lib         # Utility functions /types       # TypeScript types /supabase /migrations  # SQL migration files /seed        # Seed data files /public        # Static assets ## Database Migrations SQL files in /supabase/migrations should: - Use sequential numbering: 001, 002, etc. - Include descriptive names - Be reviewed by Cline before execution Example: 001_create_users_table.sql ## Development Workflow - Cline helps write and review code changes - Vercel automatically deploys from main branch - Database migrations reviewed by Cline before execution ## Security DO NOT read or modify: - .env files - **/config/secrets.* - Any file containing API keys or credentials Learning Resources (2025) Want to learn more about the technologies we're using? Here are some great resources: Next.js and React Official Learn Next.js Course - Interactive tutorial NextJS App Router: Modern Web Dev in 1 Hour - Quick overview Building Real-World Apps with Next.js - Practical examples Supabase Supabase From Scratch - Comprehensive course Official Quickstart Guides Real-Time Apps with Next.js and Supabase Tailwind CSS Tailwind CSS Tutorial for Beginners Official Tailwind Documentation Interactive course at Scrimba Tailwind CSS Course Other Things to Know Working with Git & GitHub Git helps you track changes in your code and collaborate with others. Here are the essential commands you'll use: Daily Development Copy # Save your changes (do this often!) git add .                                    # Stage all changed files git commit -m "Add login page"              # Save changes with a clear message # Share your changes git push origin main                        # Upload to GitHub Common Workflow Start of day : Get latest changes Copy bashCopygit pull origin main                     # Download latest code During development : Save work regularly Copy bashCopygit add . git commit -m "Clear message about changes" End of day : Share your progress Copy bashCopygit push origin main                     # Upload to GitHub Best Practices Commit often with clear messages Pull before starting new work Push completed work to share with others Use .gitignore to avoid committing sensitive files Tip : Vercel automatically deploys when you push to main! Environment Variables Store secrets in .env.local for development Add them to Vercel project settings for production Never commit .env files to Git Getting Help Use /help in Cline chat for immediate assistance Check Cline Documentation Join our Discord Community Search GitHub issues for common problems Remember: Cline is here to help at every step. Just ask for guidance or clarification when needed! Previous Installing Dev Essentials Next Understanding Context Management Last updated 20 days ago
####### HTTPS://DOCS.CLINE.BOT #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page Getting Started Improving Your Prompting Skills Exploring Cline's Tools Contributing to Cline Additional Resources Cline Documentation Welcome to the Cline documentation - your comprehensive guide to using and extending Cline's capabilities. Here you'll find resources to help you get started, improve your skills, and contribute to the project. Getting Started New to coding? We've prepared a gentle introduction: Getting Started for New Coders Improving Your Prompting Skills Want to communicate more effectively with Cline? Explore: Prompt Engineering Guide Cline Memory Bank Exploring Cline's Tools Understand Cline's capabilities: Cline Tools Guide Extend Cline with MCP Servers: MCP Overview Building MCP Servers from GitHub Building Custom MCP Servers Contributing to Cline Interested in contributing? We welcome your input: Feel free to submit a pull request Contribution Guidelines Additional Resources Cline GitHub Repository: https://github.com/cline/cline MCP Documentation: https://modelcontextprotocol.org/docs We're always looking to improve this documentation. If you have suggestions or find areas that could be enhanced, please let us know. Your feedback helps make Cline better for everyone! Next Getting Started for New Coders Last updated 16 days ago
####### HTTPS://DOCS.CLINE.BOT/GETTING-STARTED/GETTING-STARTED-NEW-CODERS/INSTALLING-DEV-ESSENTIALS #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page The Essential Tools Let Cline Install Everything What Will Happen Why These Tools Are Important Notes Additional Tips for New Coders Understanding the Terminal Understanding VS Code Features Common Features Next Steps Getting Started Getting Started for New Coders Installing Dev Essentials When you start coding, you'll need some essential development tools installed on your computer. Cline can help you install everything you need in a safe, guided way. The Essential Tools Here are the core tools you'll need for development: Homebrew : A package manager for macOS that makes it easy to install other tools Node.js & npm : Required for JavaScript and web development Git : For tracking changes in your code and collaborating with others Python : A programming language used by many development tools Additional utilities : Tools like wget and jq that help with downloading files and processing data Let Cline Install Everything Copy this prompt and paste it into Cline: Copy Hello Cline! I need help setting up my Mac for software development. Could you please help me install the essential development tools like Homebrew, Node.js, Git, Python, and any other utilities that are commonly needed for coding? I'd like you to guide me through the process step-by-step, explaining what each tool does and making sure everything is installed correctly. What Will Happen Cline will first install Homebrew, which is like an "app store" for development tools Using Homebrew, Cline will then install other essential tools like Node.js and Git For each installation step: Cline will show you the exact command it wants to run You'll need to approve each command before it runs Cline will verify each installation was successful Why These Tools Are Important Homebrew : Makes it easy to install and update development tools on your Mac Node.js & npm : Required for: Building websites with React or Next.js Running JavaScript code Installing JavaScript packages Git : Helps you: Save different versions of your code Collaborate with other developers Back up your work Python : Used for: Running development scripts Data processing Machine learning projects Notes The installation process is interactive - Cline will guide you through each step You may need to enter your computer's password for some installations. When prompted, you will not see any characters being typed on the screen. This is normal and is a security feature to protect your password. Just type your password and press Enter. Example: Copy $ /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)" Password: Type your password here, even though nothing will show up on the screen. Press Enter when you're done. All commands will be shown to you for approval before they run If you run into any issues, Cline will help troubleshoot them Additional Tips for New Coders Understanding the Terminal The Terminal is an application where you can type commands to interact with your computer. On macOS, you can open it by searching for "Terminal" in Spotlight. Example: Copy $ open -a Terminal Understanding VS Code Features Terminal in VS Code The Terminal in VS Code allows you to run commands directly from within the editor. You can open it by going to View > Terminal or by pressing Ctrl + ` . Example: Copy $ node -v v16.14.0 Document View The Document View is where you edit your code files. You can open files by clicking on them in the Explorer panel on the left side of the screen. Problems Section The Problems section in VS Code shows any errors or warnings in your code. You can access it by clicking on the lightbulb icon or by going to View > Problems . Common Features Command Line Interface (CLI) : This is a text-based interface where you type commands to interact with your computer. It might seem intimidating at first, but it's a powerful tool for developers. Permissions : Sometimes, you will need to give permissions to certain applications or commands. This is a security measure to ensure that only trusted applications can make changes to your system. Next Steps After installing these tools, you'll be ready to start coding! Return to the Getting Started with Cline for New Coders guide to continue your journey. Previous Getting Started for New Coders Next Our Favorite Tech Stack Last updated 1 month ago
####### HTTPS://DOCS.CLINE.BOT/GETTING-STARTED/GETTING-STARTED-NEW-CODERS #######

Ask or search ... Ctrl + K Cline Documentation Getting Started Getting Started for New Coders Installing Dev Essentials Our Favorite Tech Stack Understanding Context Management Model Selection Guide Improving Your Prompting Skills Prompt Engineering Guide Custom Instructions Library Cline Memory Bank Exploring Cline's Tools Cline Tools Guide Checkpoints Plan & Act Modes: A Guide to Effective AI Development MCP Servers MCP Overview MCP Quickstart Building MCP Servers from GitHub Building Custom MCP Servers Custom Model Configs AWS Bedrock GCP Vertex AI LiteLLM & Cline (using Codestral) Running Models Locally Read Me First Ollama LM Studio Powered by GitBook On this page What You'll Need Step-by-Step Setup Setting up OpenRouter API Key Your First Interaction with Cline Tips for Working with Cline FAQs Still Struggling? Getting Started Getting Started for New Coders Welcome to Cline! This guide will help you get set up and start using Cline to build your first project. What You'll Need Before you begin, make sure you have the following: VS Code: A free, powerful code editor. Download VS Code Development Tools: Essential software for coding (Homebrew, Node.js, Git, etc.). Follow our Installing Essential Development Tools guide to set these up with Cline's help (after getting setup here) Cline will guide you through installing everything you need Cline Projects Folder: A dedicated folder for all your Cline projects. On macOS: Create a folder named "Cline" in your Documents folder Path: /Users/[your-username]/Documents/Cline On Windows: Create a folder named "Cline" in your Documents folder Path: C:\Users\[your-username]\Documents\Cline Inside this Cline folder, create separate folders for each project Example: Documents/Cline/workout-app for a workout tracking app Example: Documents/Cline/portfolio-website for your portfolio Cline Extension in VS Code: The Cline extension installed in VS Code. Here's a tutorial on everything you need to get started. Step-by-Step Setup Follow these steps to get Cline up and running: Open VS Code: Launch the VS Code application. If VS Code shows "Running extensions might...", click "Allow". Open Your Cline Folder: In VS Code, open the Cline folder you created in Documents. Navigate to Extensions: Click on the Extensions icon in the Activity Bar on the side of VS Code. Search for 'Cline': In the Extensions search bar, type "Cline". Install the Extension: Click the "Install" button next to the Cline extension. Open Cline: Once installed, you can open Cline in a few ways: Click the Cline icon in the Activity Bar. Use the command palette ( CMD/CTRL + Shift + P ) and type "Cline: Open In New Tab" to open Cline as a tab in your editor. This is recommended for a better view. Troubleshooting: If you don't see the Cline icon, try restarting VS Code. What You'll See: You should see the Cline chat window appear in your VS Code editor. Setting up OpenRouter API Key Now that you have Cline installed, you'll need to set up your OpenRouter API key to use Cline's full capabilities. Get your OpenRouter API Key: Get your OpenRouter API Key Input Your OpenRouter API Key: Navigate to the settings button in the Cline extension. Input your OpenRouter API key. Select your preferred API model. Recommended Models for Coding: anthropic/claude-3.5-sonnet : Most used for coding tasks. google/gemini-2.0-flash-exp:free : A free option for coding. deepseek/deepseek-chat : SUPER CHEAP, almost as good as 3.5 sonnet OpenRouter Model Rankings Your First Interaction with Cline Now you're ready to start building with Cline. Let's create your first project folder and build something! Copy and paste the following prompt into the Cline chat window: Copy Hey Cline! Could you help me create a new project folder called "hello-world" in my Cline directory and make a simple webpage that says "Hello World" in big blue text? What You'll See: Cline will help you create the project folder and set up your first webpage. Tips for Working with Cline Ask Questions: If you're unsure about something, don't hesitate to ask Cline! Use Screenshots: Cline can understand images, so feel free to use screenshots to show him what you're working on. Copy and Paste Errors: If you encounter errors, copy and paste the error messages into Cline's chat. This will help him understand the issue and provide a solution. Speak Plainly: Cline is designed to understand plain, non-technical language. Feel free to describe your ideas in your own words, and Cline will translate them into code. FAQs What is the Terminal? The terminal is a text-based interface for interacting with your computer. It allows you to run commands to perform various tasks, such as installing packages, running scripts, and managing files. Cline uses the terminal to execute commands and interact with your development environment. How Does the Codebase Work? (This section will be expanded based on common questions from new coders) Still Struggling? Feel free to contact me, and I'll help you get started with Cline. nick | 608-558-2410 Join our Discord community: https://discord.gg/cline Previous Cline Documentation Next Installing Dev Essentials Last updated 1 month ago gettingStartedVsCodeCline